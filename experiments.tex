\section{Experiments}\label{sectexpr}

  We evaluate Lean-auto on three types of ATPs:
  \begin{enumerate}
    \item Native provers, or ATPs implemented in Lean4 itself. At present, the only general-purpose
      native prover in Lean4 is Duper \cite{DuperPaper}. Note that Lean-auto is
      used as a preprocessing step in Duper (cf. Sect. 5 of \cite{DuperPaper}).
      This is because Duper's core algorithm, which is based on the algorithm used
      in the higher-order prover Zipperposition \cite{ZipperpositionMakeWork}, has limited support for dependent
      type theory, and has difficulty handling Lean4 features like typeclasses.
    \item TPTP solvers. We chose Zipperposition because it supports HOL.
    \item SMT solvers. For this category, we chose Z3 and CVC5. Since SMT solvers
      still don't fully support HOL, we implemented a simple procedure
      (which is incomplete but sufficiently sound) to translate the HOL output of Lean-auto into FOL.
  \end{enumerate}

  Currently, Lean-auto only supports proof reconstruction for native provers,
  which utilizes a verified checker implemented in Lean-auto. An
  ongoing project Lean-smt\footnote{GitHub link: https://github.com/ufmg-smite/lean-smt}
  will provide support for SMT proof reconstruction in the future. For TPTP solvers,
  the verified checker in Lean-auto may be extended to support their proof reconstruction.

  Since we have not found suitable premise selection tools in Lean4, we emulate
  premise selection using a simple procedure. For each theorem $T$ used to evaluate
  Lean-auto, we collect all the theorems used in its human proof. The set of collected theorems
  roughly equals the set of necessary premises needed to prove $T$. Therefore, it could
  be used as a replacement for the output of premise selection.

  The evaluation dataset consists of 128 human theorems randomly drawn from the entire
  Mathlib4\footnote{Commit d5ab93e3a3afadaf265a583a92f7e7c47203b540}. A
  Lean4 constant is considered a human theorem iff it is a constant and
  is declared somewhere in a \texttt{.lean} file\footnote{We use
  \texttt{Lean.findDeclarationRanges?} to test whether a theorem is
  declared in a \texttt{.lean} file}. Evaluation is conducted on a laptop
  with \texttt{AMD Ryzen 9 7945HX} 16-Core CPU and \texttt{32GB} memory.

  \begin{figure}
  \begin{center}\begin{tabular}{| c K{6em} K{6em} K{6em} K{6em} |}
    \hline
            & Duper & Zipperposition & Z3 & CVC5 \\ \hline
    UNSAT   & 17    & 19             & 17 & 17   \\
    SAT     & 64    & 0              & 37 & 27   \\
    UNKNOWN & 47    & 109            & 74 & 84   \\ \hline
  \end{tabular}\end{center}
  \caption{Evaluation result} \label{figevalresult}
  \end{figure}

  The result of evaluation is shown in Fig. \ref{figevalresult}. \texttt{UNSAT} means
  that ATP successfully solved the translated problem, \texttt{SAT} means that
  the translated problem is not provable, and \texttt{UNKNOWN} means that the prover
  either returned unknown or timed out. Out of all the ATPs, zipperposition solved the
  most problems, with a success rate of 14.8\%, while Duper returned the least \texttt{UNKNOWN}.
  
  According to the result, when combined with ATPs, Lean-auto is already able to
  solve a small percentage of Mathlib4 problems. We expect that a much higher percentage
  of theorems in Mathlib4 can be partially automated by Lean-auto, because solving
  subgoals in the proof is much easier than proving the entire theorem automatically.